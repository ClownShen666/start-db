version: '3.3'
services:
  spark-master:
    image: cluster-apache-spark:latest
    ports:
      - "8084:8080"
      - "7077:7077"
    volumes:
      - ./apps:/opt/spark-apps
      - ./data:/opt/spark-data
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_WORKLOAD=master
    profiles:
      - cluster
  spark-worker-a:
    image: cluster-apache-spark:latest
    ports:
      - "8083:8080"
      - "7000:7000"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-a
    volumes:
      - ./apps:/opt/spark-apps
      - ./data:/opt/spark-data
    profiles:
      - cluster
  spark-worker-b:
    image: cluster-apache-spark:latest
    ports:
      - "8082:8080"
      - "7001:7000"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-b
    volumes:
      - ./apps:/opt/spark-apps
      - ./data:/opt/spark-data
    profiles:
      - cluster
  livy:
    hostname: livy-local
    image: livy:latest
    ports:
      - "8998:8998"
    volumes:
      - ./apps:/opt/spark-apps
    depends_on:
      - spark-master
      - spark-worker-a
      - spark-worker-b
    profiles:
      - cluster
  jobmanager:
    image: flink:1.17.0
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
    expose:
      - "8081"
  taskmanager:
    image: flink:1.17.0
    depends_on:
      - jobmanager
    command: taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager

  redis:
    image: redis:latest
    environment:
      REDIS_PASSWORD: 123456
    ports:
      - "6379:6379"
    expose:
      - "6379"

  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2281:2181"

  kafka:
    image: wurstmeister/kafka:2.13-2.7.0
    ports:
      - "9092:9092"
    expose:
      - "9093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_LOG_DIRS: "/kafka/logs"
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_NUM_REPLICA_FETCHERS: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - zookeeper
  mysql-local:
    image: 'mysql:5.7'
    volumes:
      - /var/lib/mysql:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD: cupid_db
      MYSQL_USER: cupid_db
      MYSQL_PASSWORD: cupid_db
      MYSQL_DATABASE: meta_data
    ports:
      - '3306:3306'

  geomesa-hbase-local:
    image: spatiotemporallab/geomesa-hbase-cupid:1.0.0
    hostname: geomesa-hbase-local
    ports:
      - '2181:2181'
      - '16000:16000'
      - '16020:16020'
  cupid-db:
    build:
      context: ./cupid-db
      dockerfile: ../cupid-db/Dockerfile
    ports:
        - "8000:8000"
    depends_on:
      - mysql-local
      - geomesa-hbase-local



#  ss-proxy:
#    image: cluster-apache-spark
##    image: ss-proxy:1.0.0
#    volumes:
#      - ./conf:/usr/local/ss-proxy/conf
#    environment:
#      PORT: 3307
#    ports:
#      - '3307:3307'
#    depends_on:
#      - cupid-db
